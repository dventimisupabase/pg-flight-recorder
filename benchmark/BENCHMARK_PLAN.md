# Benchmarking plan for pg-flight-recorder

Light benchmark suite measuring observer effect, storage growth, and bloat.

## 1. Observer effect benchmarks

### 1.1 Metrics

| Metric | Source |
|--------|--------|
| TPS impact | pgbench `--log`, mean ± stddev |
| Latency | p50, p95, p99 from pgbench logs |
| WAL overhead | `pg_wal_lsn_diff()` in idle phase |
| Sample duration | flight_recorder collection stats |

### 1.2 Test matrix

| Workload | Clients | Duration | Interval |
|----------|---------|----------|----------|
| OLTP balanced | 50 | 15 min | 180s |
| Read-heavy (90/10) | 50 | 15 min | 180s |
| Write-heavy (20/80) | 50 | 15 min | 180s |

**Estimated runtime:** ~8.5 hours for full matrix (5 iterations × 2 modes × 17 min × 3 workloads)

### 1.3 Methodology

**Interleaved A-B with alternating order:**

```bash
#!/usr/bin/env bash
set -Eeuo pipefail

# 5 iterations, alternating which mode runs first
for i in {1..5}; do
    if (( i % 2 == 1 )); then
        # Odd iterations: baseline first
        first_mode="baseline"
        second_mode="enabled"
    else
        # Even iterations: enabled first
        first_mode="enabled"
        second_mode="baseline"
    fi

    for mode in "${first_mode}" "${second_mode}"; do
        if [[ "${mode}" == "baseline" ]]; then
            psql -c "select flight_recorder.disable()"
        else
            psql -c "select flight_recorder.enable()"
        fi

        # Warmup run (discard) - normalizes cache state
        pgbench -n -M prepared --random-seed=42 \
            -c "${CLIENTS}" -j "${CLIENTS}" -T 120 \
            -f "scenarios/${WORKLOAD}.sql" > /dev/null

        # Measured run - steady state only
        pgbench -n -M prepared --random-seed=42 \
            -c "${CLIENTS}" -j "${CLIENTS}" -T 900 \
            -P 10 -r --log --log-prefix="${mode}_${i}" \
            -f "scenarios/${WORKLOAD}.sql"
    done
done
```

**Key points:**

- No forced `CHECKPOINT` (distorts results)
- 2-minute warmup run discarded before each measurement
- Alternating order eliminates systematic bias
- Fixed random seed for reproducibility
- `-M prepared` for consistent protocol
- `-P 10` progress every 10 seconds
- `-r` per-statement latency report

### 1.4 WAL measurement (idle phase)

Measure WAL per `sample()` in isolation to avoid workload noise.
Back-to-back calls without sleep — measures pure `sample()` WAL only:

```sql
-- measure WAL generated by N samples, divide by N
do $$
declare
    v_wal_before pg_lsn;
    v_wal_after pg_lsn;
    v_samples int := 20;
begin
    v_wal_before := pg_current_wal_lsn();

    for i in 1..v_samples loop
        perform flight_recorder.sample();
    end loop;

    v_wal_after := pg_current_wal_lsn();

    raise notice 'WAL per sample: % bytes',
        pg_wal_lsn_diff(v_wal_after, v_wal_before) / v_samples;
end $$;
```

### 1.5 Thresholds

Warning/critical trigger when BOTH conditions exceeded (i.e., success if EITHER is small):

| Metric | Warning | Critical |
|--------|---------|----------|
| TPS degradation | > 1% | > 3% |
| p99 latency increase | > 5% AND > 2ms | > 15% AND > 5ms |
| WAL per sample | > 10 KB | > 50 KB |
| Sample duration vs interval | > 50% | > 80% |

Example: baseline p99 = 50ms, test p99 = 52ms (4% increase, 2ms absolute).
This passes because 4% < 5% — the relative threshold is not exceeded.

## 2. Storage benchmarks

### 2.1 Measurement query

```sql
-- storage metrics using catalog stats (run ANALYZE first)
select
    c.relname as table_name,
    c.reltuples::int8 as row_count,
    pg_relation_size(c.oid) as heap_size_bytes,
    pg_indexes_size(c.oid) as index_size_bytes,
    pg_total_relation_size(c.oid) as total_size_bytes
from pg_class as c
inner join pg_namespace as n
    on n.oid = c.relnamespace
where
    n.nspname = 'flight_recorder'
    and c.relkind = 'r'
order by pg_total_relation_size(c.oid) desc;
```

### 2.2 Row size measurement (data-driven projections)

```sql
-- measure actual row sizes, don't use magic constants
-- for ring buffers (bounded), full scan is acceptable
select
    'samples_ring' as table_name,
    count(*) as row_count,
    avg(pg_column_size(t.*))::numeric(10, 2) as avg_row_bytes,
    pg_relation_size('flight_recorder.samples_ring') as heap_bytes,
    pg_indexes_size('flight_recorder.samples_ring') as index_bytes
from flight_recorder.samples_ring as t;

-- for large tables, use sampling
select
    avg(pg_column_size(t.*))::numeric(10, 2) as avg_row_bytes
from flight_recorder.statement_snapshots as t
tablesample bernoulli(1);
```

### 2.3 Projection formula

```sql
-- project daily growth from measured values
with row_sizes as (
    select
        'samples_ring' as table_name,
        avg(pg_column_size(t.*)) as avg_row_bytes
    from flight_recorder.samples_ring as t
)
select
    table_name,
    avg_row_bytes,
    -- samples per day at 180s interval
    (86400.0 / 180) as samples_per_day,
    -- heap growth
    (86400.0 / 180) * avg_row_bytes / 1024 / 1024 as heap_mb_per_day,
    -- include index overhead (~40% typical)
    (86400.0 / 180) * avg_row_bytes * 1.4 / 1024 / 1024 as total_mb_per_day
from row_sizes;
```

### 2.4 Test scenarios

| Scenario | Duration | Purpose |
|----------|----------|---------|
| Idle | 4h | Baseline growth (recorder only) |
| Light load | 4h | Typical usage pattern |

## 3. Bloat benchmarks

### 3.1 Lightweight tracking (every 5 min)

Use `pg_stat_user_tables` — no table scans:

```sql
select
    relname,
    n_live_tup,
    n_dead_tup,
    round(
        100.0 * n_dead_tup / nullif(n_live_tup + n_dead_tup, 1),
        2
    ) as dead_pct,
    n_tup_upd,
    n_tup_hot_upd,
    round(
        100.0 * n_tup_hot_upd / nullif(n_tup_upd, 1),
        2
    ) as hot_pct,
    last_autovacuum
from pg_stat_user_tables
where
    schemaname = 'flight_recorder'
    and relname like '%\_ring';
```

### 3.2 Delta-based HOT measurement

Cumulative counters need baseline subtraction:

```sql
-- capture baseline at test start
create temp table bloat_baseline as
select
    relname,
    n_tup_upd,
    n_tup_hot_upd,
    n_dead_tup
from pg_stat_user_tables
where schemaname = 'flight_recorder';

-- at test end, compute deltas
select
    c.relname,
    c.n_tup_upd - b.n_tup_upd as updates_during_test,
    c.n_tup_hot_upd - b.n_tup_hot_upd as hot_updates_during_test,
    round(
        100.0 * (c.n_tup_hot_upd - b.n_tup_hot_upd)
        / nullif(c.n_tup_upd - b.n_tup_upd, 0),
        2
    ) as hot_pct_during_test
from pg_stat_user_tables as c
inner join bloat_baseline as b
    on c.relname = b.relname
where c.schemaname = 'flight_recorder';
```

### 3.3 Precise bloat (end of test only)

```sql
-- run once at end, not during test
select *
from pgstattuple_approx('flight_recorder.samples_ring');
```

### 3.4 Thresholds

| Metric | Healthy | Warning |
|--------|---------|---------|
| HOT update % (ring) | > 85% | < 70% |
| Dead tuple % (ring) | < 10% | > 20% |

### 3.5 Sample duration check (overrun detection)

One cheap safeguard — detect if `sample()` takes longer than interval:

```sql
select
    started_at,
    duration_ms,
    case
        when duration_ms > 180000 * 0.8 then 'CRITICAL: >80% of interval'
        when duration_ms > 180000 * 0.5 then 'WARNING: >50% of interval'
        else 'OK'
    end as status
from flight_recorder.collection_stats
where collection_type = 'sample'
order by started_at desc
limit 10;
```

## 4. Prerequisites

```bash
#!/usr/bin/env bash
set -Eeuo pipefail

# verify flight_recorder is installed
psql -tAc "select 1 from pg_extension where extname = 'pg_cron'" | grep -q 1 \
    || { echo "ERROR: pg_cron extension required"; exit 1; }

psql -tAc "select 1 from pg_namespace where nspname = 'flight_recorder'" | grep -q 1 \
    || { echo "ERROR: flight_recorder not installed (run install.sql)"; exit 1; }

# verify pgstattuple for bloat measurement
psql -tAc "select 1 from pg_extension where extname = 'pgstattuple'" | grep -q 1 \
    || { echo "ERROR: CREATE EXTENSION pgstattuple required"; exit 1; }

echo "Prerequisites OK"
```

## 5. Files to create

```
benchmark/
  measure_observer_effect.sh    # A-B interleaved TPS/latency
  measure_storage.sh            # storage growth tracking
  measure_bloat.sh              # HOT ratio + dead tuples
  scenarios/
    oltp_balanced.sql           # 50% read, 50% write
    oltp_read_heavy.sql         # 90% read, 10% write
    oltp_write_heavy.sql        # 20% read, 80% write
  lib/
    statistical_analysis.py     # mean, stddev, 95% CI, paired comparison
```

## 6. Implementation order

1. Create workload scenarios (test manually with pgbench first)
2. Create `measure_observer_effect.sh`
3. Create `lib/statistical_analysis.py`
4. Create `measure_storage.sh`
5. Create `measure_bloat.sh`
6. Update `benchmark/README.md`

## 7. What we're NOT doing

- LWLock contention tracking
- Memory overhead measurement
- Crash recovery testing
- High-churn / many-tables scenarios
- CI integration
- Config-driven runner
- Separate benchmark schema
- Multi-version PostgreSQL testing

## 8. Success criteria

| Area | Target |
|------|--------|
| TPS degradation | < 1% |
| p99 latency increase | < 5% OR < 2ms |
| Storage projections | within ±20% of actual |
| HOT update % (ring) | > 85% |
| Dead tuple % (ring) | < 10% |

Note: p99 passes if EITHER relative OR absolute threshold is met (consistent with section 1.5).
